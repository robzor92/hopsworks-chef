#!/usr/bin/env bash

#
# This script converts ipython notebooks to/from python programs
#

help() {
    echo ""
    echo "usage: $0 path hdfs_username jupyter_path output_path conversion_dir conversion_type"
    echo ""
    exit 1
}

if [ "$#" -ne 6 ] ; then
    help
fi

staging_dir=<%= node['hopsworks']['staging_dir'] %>
cd $staging_dir
if [ $? -ne 0 ] ; then
    echo "The staging directory does not exist. Cannot continue. Missing dir: <%= node['hopsworks']['staging_dir'] %>"
    exit 2
fi

conversion_dir="$staging_dir"/ipython_conversions/"$5"
function finish {
    rm -rf "$conversion_dir"
}
trap finish EXIT

mkdir -p "$conversion_dir"

if [ $? -ne 0 ] ; then
    echo "Could not create directory in the staging directory for converting iPython notebook. Problem dir: <%= node['hopsworks']['staging_dir'] %>/ipython_conversions as user $USER"
    exit 3
fi    

cd "$conversion_dir"

filename=$(basename "$1")
dirname=$(dirname "$1")

base=$(echo "$filename" | cut -f 1 -d '.')

# Stage the jupyter notebook before converting locally and uploading back to hdfs
<%= node['hops']['base_dir'] %>/bin/hdfs dfs -copyToLocal "$1" tmp.ipynb
if [ $? -ne 0 ] ; then
    echo "Problem staging from hdfs ipython notebook: $1"
    exit 4
fi

if [ ! -f "$3"/bin/jupyter ]; then
    echo "Is Python enabled? No jupyter binary found on path $3/bin/jupyter"
    exit 5
fi

if [ "$6" = "PY" ]; then

  "$3"/bin/jupyter nbconvert --to python tmp.ipynb
  if [ $? -ne 0 ] ; then
      echo "Problem converting ipython notebook to python program: $1"
      exit 6
  fi

  printf '%s\n%s\n%s\n%s\n%s\n%s\n' "from pyspark.sql import SparkSession" "from pyspark.sql import SQLContext" "spark=SparkSession.builder.enableHiveSupport().getOrCreate()" "sc=spark.sparkContext" "sqlContext=SQLContext(sc)" "$(cat tmp.py)" > tmp.py

  # Over-write any old version on hdfs
  <%= node['hops']['base_dir'] %>/bin/hdfs dfs -copyFromLocal -f tmp.py "$4"
  if [ $? -ne 0 ] ; then
      echo "Problem copying converted ipython program back to hdfs: $4"
      exit 7
  fi

  # Current user should have hdfs superuser privileges
  <%= node['hops']['base_dir'] %>/bin/hdfs dfs -chown "$2" "$4"
  if [ $? -ne 0 ] ; then
      echo "Problem changing ownership of converted ipython program in hdfs: $dirname/${base}.py chown to user $2"
      exit 8
  fi

else

  "$3"/bin/jupyter nbconvert --to html tmp.ipynb
  if [ $? -ne 0 ] ; then
      echo "Problem converting ipython notebook to html: $1"
      exit 6
  fi

  cat ./tmp.html

fi


